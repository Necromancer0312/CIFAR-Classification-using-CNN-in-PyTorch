{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfrom_model = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding = 4),\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomAffine(0, translate = (0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root = '.', train = True, transform = transfrom_model, download = True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = '.', train = False, transform = transfrom_model, download = True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = 128, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = 128, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(train_dataset.targets))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten(1)\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.dropout(x, p = 0.2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p = 0.2)\n",
    "        out = self.fc2(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary_model = summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = (len(train_loader)) * 2 + len(test_loader)\n",
    "total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "train_losses = np.zeros(n_epochs)\n",
    "test_losses = np.zeros(n_epochs)\n",
    "train_accuracies = np.zeros(n_epochs)\n",
    "test_accuracies = np.zeros(n_epochs)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_str = str(epoch + 1).rjust(len(str(n_epochs)), \" \")\n",
    "    with tqdm(total = total_len, desc = f\"Epoch [ {epoch_str}/{n_epochs} ] : \") as pbar:\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update(1)\n",
    "\n",
    "        n_correct = 0\n",
    "        n_total = 0\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs_train = model(inputs)\n",
    "            _, predictions_train = torch.max(outputs_train, 1)\n",
    "            n_correct += (predictions_train == targets).sum().item()\n",
    "            n_total += targets.shape[0]\n",
    "            loss_train = criterion(outputs_train, targets)\n",
    "            train_loss.append(loss_train.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "        train_acc_epoch = n_correct / n_total\n",
    "        train_loss = np.mean(train_loss)\n",
    "        train_losses[epoch] = train_loss\n",
    "        train_accuracies[epoch] = train_acc_epoch\n",
    "\n",
    "        n_correct = 0\n",
    "        n_total = 0\n",
    "        test_loss = []\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs_test = model(inputs)\n",
    "            _, predictions_test = torch.max(outputs_test, 1)\n",
    "            n_correct += (predictions_test == targets).sum().item()\n",
    "            n_total += targets.shape[0]\n",
    "            loss_test = criterion(outputs_test, targets)\n",
    "            test_loss.append(loss_test.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "        test_acc_epoch = n_correct / n_total\n",
    "        test_loss = np.mean(test_loss)\n",
    "        test_losses[epoch] = test_loss\n",
    "        test_accuracies[epoch] = test_acc_epoch\n",
    "        pbar.set_description(f\"Epoch [ {epoch_str}/{n_epochs} ] \")\n",
    "        pbar.set_postfix({'Train Accuracy' : f\"{train_acc_epoch:.4f}\", 'Train Loss' : f\"{train_loss:.4f}\", 'Test Accuracy' : f\"{test_acc_epoch:.4f}\", 'Test Loss' : f\"{test_loss:.4f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracies, label = 'Train Accuracy')\n",
    "plt.plot(test_accuracies, label = 'Test Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label = 'Train Loss')\n",
    "plt.plot(test_losses, label = 'Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct = 0\n",
    "n_total = 0\n",
    "with tqdm(total = (len(train_loader) + len(test_loader)), desc = \"Calculating accuracies : \") as pbar:\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs_train_final = model(inputs)\n",
    "        _, predictions_train_final = torch.max(outputs_train_final, 1)\n",
    "        n_correct += (predictions_train_final == targets).sum().item()\n",
    "        n_total += targets.shape[0]\n",
    "        pbar.update(1)\n",
    "\n",
    "    train_acc = n_correct / n_total\n",
    "\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs_test_final = model(inputs)\n",
    "        _, predictions_test_final = torch.max(outputs_test_final, 1)\n",
    "        n_correct += (predictions_test_final == targets).sum().item()\n",
    "        n_total += targets.shape[0]\n",
    "        pbar.update(1)\n",
    "\n",
    "    test_acc = n_correct / n_total\n",
    "    pbar.set_description(\"Process completed \")\n",
    "    # pbar.set_postfix_str(f\"Train Accuracy : {train_acc:.4f}, Test Accuracy : {test_acc:.4f}\")  \n",
    "    print(f\"\\nTrain Accuracy : {train_acc:.4f}, Test Accuracy : {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "  \"\"\"\n",
    "  This function prints and plots the confusion matrix.\n",
    "  Normalization can be applied by setting `normalize=True`.\n",
    "  \"\"\"\n",
    "  if normalize:\n",
    "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "      print(\"Normalized confusion matrix\")\n",
    "  else:\n",
    "      print('Confusion matrix, without normalization')\n",
    "\n",
    "  print(cm)\n",
    "\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(classes))\n",
    "  plt.xticks(tick_marks, classes, rotation=45)\n",
    "  plt.yticks(tick_marks, classes)\n",
    "\n",
    "  fmt = '.2f' if normalize else 'd'\n",
    "  thresh = cm.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "      plt.text(j, i, format(cm[i, j], fmt),\n",
    "               horizontalalignment=\"center\",\n",
    "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_dataset.data\n",
    "y_test = np.array(test_dataset.targets)\n",
    "p_test = np.array([])\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "    outputs_cm = model(inputs)\n",
    "    _, prediction_cm = torch.max(outputs_cm, 1)\n",
    "    p_test = np.concatenate((p_test, prediction_cm.cpu().numpy()))\n",
    "\n",
    "cm = confusion_matrix(y_test, p_test)\n",
    "plot_confusion_matrix(cm, list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = p_test.astype(np.uint8)\n",
    "misclassified_idx = np.where(p_test != y_test)[0]\n",
    "sample_idx = np.random.choice(misclassified_idx, 10, replace=False)\n",
    "plt.figure(figsize=(32,32))\n",
    "for j, i in enumerate(sample_idx):\n",
    "  plt.subplot(10, 1, j + 1)\n",
    "  plt.axis('off')\n",
    "  plt.imshow(x_test[i].reshape(32,32,3))\n",
    "  plt.title(\"True label: %s Predicted: %s\" % (labels[y_test[i]], labels[p_test[i]]));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
